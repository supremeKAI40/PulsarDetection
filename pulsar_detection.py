# -*- coding: utf-8 -*-
"""Pulsar Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xcWN2HqFNT0mrSyhrw-XI2kR5HVymQUx
"""

!pip install jovian --upgrade --quiet
!pip install opendatasets --upgrade --quiet

import opendatasets as od

dataset_url = 'https://www.kaggle.com/colearninglounge/predicting-pulsar-starintermediate?select=pulsar_data_train.csv'
od.download(dataset_url)

import pandas as pd

dataset= pd.read_csv('/content/predicting-pulsar-starintermediate/pulsar_data_train.csv')
print(dataset)

"""Checking the columns or the features, I am going to work with. It is important to know these, because sometimes dataset has some parameters which might not be equally important for our work and we can work without that particular column, that can be known with more and more data visualisation. """

dataset.columns

"""We can see there are 8-9 columns and for pulsars they look pretty important. I will decide the importance of the features in feature selection."""

dataset.head(9)

"""I get one important insight from the above table, that is there are some values which are NAN, empty or infinite but they will be treated as outliers only.

Checking the data to gain more intuitive insights, which is always a good practice.
"""

dataset.describe(include='all')

"""As I could earlier see NAN values, thus going for the important statistical parameters using the describle function. I can see that although total elements are 12528 but some columns have entries less than that, that is there are empty pockets.

It will be more clear if we try to form these data distribution. As I can see the describe function gives me parameters for integrated profile as well as DM-SNR curve. 

Physically speaking, one major parameter for Pulsars are indeed Dispersion Measure and how it behaves with Signal-to-Noise Ratio. 
"""

dataset.dtypes

"""Thus I can now be sure of one thing, all are integer or numeric type features, there is nothing here which are textual or need to be taken care of.

## Visualisation of data 

I will be using seaborn and matplotlib to make some visual insights for the data. I will import them here for now.
"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(dataset.isnull(), yticklabels=False, cbar=False, cmap='viridis')

"""As suspected the three columns are indeed showing a lot of empty values

Trying to find where these empty values are: 
"""

dataset.isnull().sum()

dataset['target_class'].tail(10)

"""To check how many positive candidates are there which will be actually helpful in training my model to detect pulsars."""

count= len(dataset[dataset['target_class']==1])
print("Number of positive candidates: {}".format(count))
print("Number of negative candidates: {}".format(len(dataset)-count))

dataset.columns[:-1].size
fig, axes = plt.subplots(nrows=len(dataset.columns[:-1]),ncols=1,  figsize=(15, 40))
for i in range(len(dataset.columns[:-1])):
    feature = dataset.columns[i]
    plt.figure(figsize = (5, 5))
    data=dataset.copy()
    sns.histplot(x=data[feature].dropna(), ax=axes[i])

"""There indeed is some need of data normalisation as although almost all data is normalised functions but still we cannot afford to have a biased data.

Target Class based plotting can give us more help to know what are the trends for pulsars and what are the trends for other objects in the dataset.
"""

data_copy= dataset.copy()
for features in dataset.columns[:-1]:
    plt.figure(figsize = (10, 5))
    sns.boxplot(x = 'target_class', y = features, data = data_copy)
    plt.grid()
    plt.show()

"""Now some data was missing, I can go in two ways, either to just ignore those data points completely, or to somehow predict those missing values to a very good accuracy and then consider that filled dataset for model.

I will go for the second choice as you can already see, there are very less positive pulsars to train the model for true results, we cannot afford to discard any of those data. 

Perhaps if we know how much the 3 columns with missing values are related with the other parameters, we can choose to ignore that input feature in the model. 

For now I will try to fill in the values and consider complete data or I will try to ignore some features, its upto my experimentation.
"""

dataset.isnull().sum()
len(dataset)
dataset.isnull().sum()/len(dataset) * 100

"""Excess curtosis has 13% of the values as null and Std. Deviation of DM-SNR curve is also pretty close to 10%

Lets try to form a dataset with null value data points only to be computed by machine.

"""

null_dataset= dataset[dataset.isnull().any(axis=1)]
null_dataset

length=len(null_dataset)
length2=len(null_dataset[null_dataset[' Excess kurtosis of the integrated profile'].isnull() & 
      null_dataset[' Standard deviation of the DM-SNR curve'].isnull()])
length3=len(null_dataset[null_dataset[' Excess kurtosis of the integrated profile'].isnull() & 
      null_dataset[' Skewness of the DM-SNR curve'].isnull()])
length4= len(null_dataset[null_dataset[' Skewness of the DM-SNR curve'].isnull() &  
      null_dataset[' Standard deviation of the DM-SNR curve'].isnull()])
length5= len(null_dataset[null_dataset[' Excess kurtosis of the integrated profile'].isnull() & 
      null_dataset[' Standard deviation of the DM-SNR curve'].isnull() & 
      null_dataset[' Skewness of the DM-SNR curve'].isnull()])
print(length)
print(length2)
print(length3)
print(length4)
print(length5)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
plt.figure(figsize = (10, 10))
corr_mat = dataset.corr()
sns.heatmap(corr_mat, xticklabels = corr_mat.columns, yticklabels = corr_mat.columns, annot=True)

"""I will Drop some columns based on the outliers in them, their correlation with other features as well as how much of empty values were there."""

dataset_drop= dataset.copy()
dataset_drop=dataset_drop.dropna(axis=1)
dataset_drop.columns

dataset_drop.head(15)

"""##DataLoader and Pytorch-ready data"""

input_cols= [title for title in dataset_drop.columns[:-1]]
output_cols= [dataset_drop.columns[-1]]
input_cols, output_cols

inputs_array = dataset_drop[input_cols].to_numpy()
targets_array = dataset_drop[output_cols].to_numpy()
inputs_array, targets_array

targets_array.shape

dataset_drop[input_cols].describe()

import torch

inputs= torch.tensor(inputs_array, dtype=torch.float32)
targets= torch.tensor(targets_array, dtype=torch.float32)

targets.shape

from torch.utils.data import DataLoader,TensorDataset,random_split

data=TensorDataset(inputs, targets)

"""Separating some part of train data for validation. As there are not a lot of Pulsar Candidates, handling data carefully becomes very important."""

val_percent=0.11
num_rows= len(dataset_drop)
val_size = int(num_rows * val_percent)
train_size = num_rows - val_size
train_ds, val_ds= random_split(data,[train_size, val_size])

len(train_ds), len(val_ds)

batch_size=128

train_loader = DataLoader(train_ds, batch_size, shuffle=True)
val_loader = DataLoader(val_ds, batch_size)

for xb, yb in train_loader:
    print("inputs:", xb.size())
    print("outputs:", yb.size())
    break

input_size= len(input_cols)
output_size= len(output_cols)
input_size,output_size



"""##Outlier Treatment"""

dataset_drop.describe()

Q1 = dataset_drop.quantile(0.25)
Q3 = dataset_drop.quantile(0.75)
IQR = Q3 - Q1
lower_range= Q1-(1.5 * IQR)
upper_range= Q3+(1.5 * IQR)
print('Number of Outliers (Percentage):')
((dataset_drop < (lower_range)) | (dataset_drop > (upper_range))).sum()/len(dataset_drop) * 100

"""As we can see Mean of DM-SNR curve has a lot of Outliers, which should be taken care of."""

for cols in dataset_drop.columns[:-1]:
  dataset_drop[cols] = np.where(dataset_drop[cols]>upper_range[cols],
                                    upper_range[cols],dataset_drop[cols])
  dataset_drop[cols] = np.where(dataset_drop[cols]<lower_range[cols],
                                    lower_range[cols],dataset_drop[cols])
dataset_drop.describe()

cols = list(dataset_drop.columns)
plt.figure(figsize=(10,8))
plt.title('Final data')
dataset_drop.boxplot(vert=0, column=cols)
plt.xlim(-200, 1300)

inputs.shape, targets.shape

import torch

def accuracy(outputs, targets):
    pred_rounded = outputs[1].round()
    return torch.tensor(pred_rounded.eq(targets).sum() / len(targets))

len(dataset_drop)

class PulsarLogisticRegression(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear= nn.Linear(input_size,output_size)
        #self.activation= nn.ReLU()
        #self.linear2= nn.Linear(3, output_size)
        self.norm= nn.Sigmoid()

        
    def forward(self,xb):
        out= self.linear(xb)
        #out=self.activation(out)
        #out=self.linear2(out)
        out=self.norm(out)
        return out

    def training_step(self, batch):
        inputs, targets = batch 
        # Generate predictions
        out = self(inputs)          
        # Calcuate loss
        loss = nn.BCELoss()                         # fill this
        loss_t= loss(out,targets)
        return loss_t
    
    def validation_step(self, batch):
        inputs, targets = batch
        # Generate predictions
        out = self(inputs)
        # Calculate loss
        loss = nn.BCELoss()
        loss_v= loss(out,targets)
        acc = accuracy(out, targets)        # Calculate accuracy
        return {'val_loss': loss_v, 'val_acc': acc} # fill this    
        
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}
    
    def epoch_end(self, epoch, result, num_epochs):
        # Print result every 20th epoch
        #if (epoch+1) % 20 == 0 or epoch == num_epochs-1:
        print("Epoch [{}], val_loss: {:.4f}, val_acc: {:.6f}".format(epoch+1, result['val_loss'], result['val_acc']))

model = PulsarLogisticRegression()
model.linear

list(model.parameters())

def evaluate(model, val_loader):
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    history = []
    optimizer = opt_func(model.parameters(), lr, momentum=0.9)
    for epoch in range(epochs):
        # Training Phase 
        for batch in train_loader:
            loss = model.training_step(batch)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        model.epoch_end(epoch, result, epochs)
        history.append(result)
    return history

result = evaluate(model, val_loader) # Use the the evaluate function
print(result)

history1= fit(10,0.001,model,train_loader,val_loader)

history1 += fit(40,0.001,model,train_loader,val_loader)

def plot_losses(history):
    train_losses = [x.get('train_loss') for x in history]
    val_losses = [x['val_loss'] for x in history]
    plt.plot(train_losses, '-bx')
    plt.plot(val_losses, '-rx')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend(['Training', 'Validation'])
    plt.title('Loss vs. No. of epochs');

plot_losses(history1)

test_datasetURL="https://www.kaggle.com/colearninglounge/predicting-pulsar-starintermediate?select=pulsar_data_test.csv"
od.download(test_datasetURL)

import torchvision.transforms as transforms

test_dataset= pd.read_csv('/content/predicting-pulsar-starintermediate/pulsar_data_test.csv')

test_dataset.columns

test_dataset_drop= test_dataset.copy()
test_dataset_drop=test_dataset_drop.drop([' Excess kurtosis of the integrated profile', 
                                     ' Skewness of the DM-SNR curve', 
                                     ' Standard deviation of the DM-SNR curve'], axis=1)
test_dataset_drop.columns

test_dataset_drop

input_cols= [title for title in dataset_drop.columns[:-1]]
output_cols= [dataset_drop.columns[-1]]

test_inputs_array = test_dataset_drop[input_cols].to_numpy()
test_targets_array = test_dataset_drop[output_cols].to_numpy()

test_inputs= torch.tensor(test_inputs_array, dtype=torch.float32)
test_targets= torch.tensor(test_targets_array, dtype=torch.float32)

test_inputs.size(), test_targets.size()

test_data=TensorDataset(test_inputs, test_targets)
test_loader = DataLoader(test_data, 256)

test_inputs_array, test_targets_array

for xb,yb in test_loader:
    print("inputs:", xb.size())
    print("outputs:", yb.size())
    break

def predict(test_loader, model):
    yhat = model(test_loader)
    # retrieve numpy array
    yhat = yhat.detach().numpy()
    return yhat

#result = predict(test_loader,model)
result2 = evaluate(model, val_loader) # Use the the evaluate function
print(result2)

